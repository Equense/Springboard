{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2: Obesity in America\n",
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that I am in the correct directory and change if need be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capstone2_2.ipynb               \u001b[34mdata\u001b[m\u001b[m/\n",
      "Capstone_BRFSS_Obesity_CSV.csv  \u001b[34mfigures\u001b[m\u001b[m/\n",
      "DataWrangling_Capstone2.ipynb   \u001b[34mmodels\u001b[m\u001b[m/\n",
      "ProjectProposal_Capstone2.pdf\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import my dataset using read_csv and taking a look at the first 5 rows to get an idea of what the dataframe looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Capstone_BRFSS_Obesity_CSV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a file structure to store my data, figures and models I create.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is springboard/Capstone2Project\n"
     ]
    }
   ],
   "source": [
    "path = 'springboard/Capstone2Project'\n",
    "print (\"The current working directory is %s\" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n"
     ]
    }
   ],
   "source": [
    "mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: figures: File exists\n"
     ]
    }
   ],
   "source": [
    "mkdir figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: models: File exists\n"
     ]
    }
   ],
   "source": [
    "mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I want to gain an understanding of what my data looks like, and what might need to happen to make it cleaner to work with later on. First, I am going to drop some columns I don't need.  \n",
    "-YearEnd is the same as YearStart, DataSource is the same for all observations, Data Footnote Symbol is unnecessary because we have the footnote itself, and we don't need to know confidence limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['YearEnd', 'Datasource', 'Data_Value_Unit', 'Data_Value_Footnote_Symbol', 'Data_Value_Type', 'DataValueTypeID', 'Data_Value_Alt', 'Low_Confidence_Limit', 'High_Confidence_Limit '], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I am going to take a look at null values and data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53392 entries, 0 to 53391\n",
      "Data columns (total 24 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   YearStart                  53392 non-null  int64  \n",
      " 1   LocationAbbr               53392 non-null  object \n",
      " 2   LocationDesc               53392 non-null  object \n",
      " 3   Class                      53392 non-null  object \n",
      " 4   Topic                      53392 non-null  object \n",
      " 5   Question                   53392 non-null  object \n",
      " 6   Data_Value                 48346 non-null  float64\n",
      " 7   Data_Value_Footnote        5046 non-null   object \n",
      " 8   Sample_Size                48346 non-null  float64\n",
      " 9   Total                      1907 non-null   object \n",
      " 10  Age(years)                 11438 non-null  object \n",
      " 11  Education                  7628 non-null   object \n",
      " 12  Gender                     3814 non-null   object \n",
      " 13  Income                     13349 non-null  object \n",
      " 14  Race/Ethnicity             15256 non-null  object \n",
      " 15  GeoLocation                52384 non-null  object \n",
      " 16  ClassID                    53392 non-null  object \n",
      " 17  TopicID                    53392 non-null  object \n",
      " 18  QuestionID                 53392 non-null  object \n",
      " 19  LocationID                 53392 non-null  int64  \n",
      " 20  StratificationCategory1    53392 non-null  object \n",
      " 21  Stratification1            53392 non-null  object \n",
      " 22  StratificationCategoryId1  53392 non-null  object \n",
      " 23  StratificationID1          53392 non-null  object \n",
      "dtypes: float64(2), int64(2), object(20)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53392, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YearStart                    0.000000\n",
       "LocationAbbr                 0.000000\n",
       "LocationDesc                 0.000000\n",
       "Class                        0.000000\n",
       "Topic                        0.000000\n",
       "Question                     0.000000\n",
       "Data_Value                   0.094509\n",
       "Data_Value_Footnote          0.905491\n",
       "Sample_Size                  0.094509\n",
       "Total                        0.964283\n",
       "Age(years)                   0.785773\n",
       "Education                    0.857132\n",
       "Gender                       0.928566\n",
       "Income                       0.749981\n",
       "Race/Ethnicity               0.714264\n",
       "GeoLocation                  0.018879\n",
       "ClassID                      0.000000\n",
       "TopicID                      0.000000\n",
       "QuestionID                   0.000000\n",
       "LocationID                   0.000000\n",
       "StratificationCategory1      0.000000\n",
       "Stratification1              0.000000\n",
       "StratificationCategoryId1    0.000000\n",
       "StratificationID1            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high percentage of Race/Ethnicity, Income, Gender, Education, Age, and Total are null. We can delete these columns because these attributes are categorized neatly for us in the stratification columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Race/Ethnicity', 'Income', 'Gender', 'Education', 'Age(years)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Total'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_Value_Footnote also has a high percentage of null values, lets look at why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Data not available because sample size is insufficient.',\n",
       "       'Data not available because sample size is insufficient.  If data only missing for the confidence interval, the confidence interval was not calculated.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Data_Value_Footnote'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    48346\n",
       "True      5046\n",
       "Name: Data_Value_Footnote, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notnull(df['Data_Value_Footnote']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     48346\n",
       "False     5046\n",
       "Name: Sample_Size, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notnull(df['Sample_Size']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for which states do we have null values?\n",
    "df_group = df.groupby(['Data_Value_Footnote', 'LocationDesc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the data value footnotes indicate rows where the sample size is insufficient, which accounts for 5,046 of our observations.  This also accounts for our null values in the Sample_Size column. So we will drop the rows where the sample size was insufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Data_Value'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Data_Value_Footnote'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48346 entries, 0 to 53386\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   YearStart                  48346 non-null  int64  \n",
      " 1   LocationAbbr               48346 non-null  object \n",
      " 2   LocationDesc               48346 non-null  object \n",
      " 3   Class                      48346 non-null  object \n",
      " 4   Topic                      48346 non-null  object \n",
      " 5   Question                   48346 non-null  object \n",
      " 6   Data_Value                 48346 non-null  float64\n",
      " 7   Sample_Size                48346 non-null  float64\n",
      " 8   GeoLocation                47338 non-null  object \n",
      " 9   ClassID                    48346 non-null  object \n",
      " 10  TopicID                    48346 non-null  object \n",
      " 11  QuestionID                 48346 non-null  object \n",
      " 12  LocationID                 48346 non-null  int64  \n",
      " 13  StratificationCategory1    48346 non-null  object \n",
      " 14  Stratification1            48346 non-null  object \n",
      " 15  StratificationCategoryId1  48346 non-null  object \n",
      " 16  StratificationID1          48346 non-null  object \n",
      "dtypes: float64(2), int64(2), object(13)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets rename some of our columns so they are more descriptive of what they contain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'YearStart':'Year', 'LocationDesc':'Location', 'Data_Value':'Percent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closer at the unique values in the data set, it appears there are 55 locations.  We only want to look at the 50 states, so lets identify which are not states and drop those from our data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                            6\n",
       "LocationAbbr                   55\n",
       "Location                       55\n",
       "Class                           3\n",
       "Topic                           3\n",
       "Question                        9\n",
       "Percent                       669\n",
       "Sample_Size                  8123\n",
       "GeoLocation                    54\n",
       "ClassID                         3\n",
       "TopicID                         3\n",
       "QuestionID                      9\n",
       "LocationID                     55\n",
       "StratificationCategory1         6\n",
       "Stratification1                28\n",
       "StratificationCategoryId1       6\n",
       "StratificationID1              28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'National', 'Alaska', 'Arizona', 'Arkansas',\n",
       "       'California', 'Connecticut', 'Colorado', 'Delaware', 'Florida',\n",
       "       'District of Columbia', 'Georgia', 'Guam', 'Hawaii', 'Idaho',\n",
       "       'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
       "       'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "       'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
       "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "       'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "       'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina',\n",
       "       'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont',\n",
       "       'Virginia', 'West Virginia', 'Washington', 'Wisconsin', 'Wyoming',\n",
       "       'Virgin Islands'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_states = ['National', 'Guam', 'District of Columbia', 'Puerto Rico', 'Virgin Islands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Location'].isin(non_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Sample_Size</th>\n",
       "      <th>LocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45629.000000</td>\n",
       "      <td>45629.000000</td>\n",
       "      <td>45629.000000</td>\n",
       "      <td>45629.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013.242762</td>\n",
       "      <td>31.176254</td>\n",
       "      <td>2032.622806</td>\n",
       "      <td>29.198054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.690712</td>\n",
       "      <td>10.220526</td>\n",
       "      <td>2532.787103</td>\n",
       "      <td>15.622223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2444.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>77.600000</td>\n",
       "      <td>36868.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year       Percent   Sample_Size    LocationID\n",
       "count  45629.000000  45629.000000  45629.000000  45629.000000\n",
       "mean    2013.242762     31.176254   2032.622806     29.198054\n",
       "std        1.690712     10.220526   2532.787103     15.622223\n",
       "min     2011.000000      1.900000     50.000000      1.000000\n",
       "25%     2011.000000     24.100000    578.000000     17.000000\n",
       "50%     2013.000000     30.700000   1201.000000     29.000000\n",
       "75%     2015.000000     37.000000   2444.000000     42.000000\n",
       "max     2016.000000     77.600000  36868.000000     56.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2011-01-01\n",
       "1       2011-01-01\n",
       "2       2011-01-01\n",
       "3       2011-01-01\n",
       "4       2011-01-01\n",
       "           ...    \n",
       "53301   2016-01-01\n",
       "53302   2016-01-01\n",
       "53303   2016-01-01\n",
       "53305   2016-01-01\n",
       "53309   2016-01-01\n",
       "Name: Year, Length: 45629, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['Year'], format='%Y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
